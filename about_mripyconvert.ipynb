{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About mrpyconvert\n",
    "mrpyconvert is a python module for converting dicom files to nifti in a bids-compatible file structure. It uses dcm2niix for conversion, which must be installed separately (https://github.com/rordenlab/dcm2niix). It was developed at the University of Oregon and has not been tested on other systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required dependencies\n",
    "python 3.7 (it might work on lower python 3 versions but I haven't checked)  \n",
    "dcm2niix https://github.com/rordenlab/dcm2niix  \n",
    "jq https://stedolan.github.io/jq/  \n",
    "pydicom https://pydicom.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicom folder structure\n",
    "mrpyconvert assumes that dicoms are organized into separate folders by series, with folder names that include the series description. It provides a function for sorting your dicoms if they are not already organized in this manner. Arguments are input directory (pathlike object), output directory (pathlike object), and an optional flag to use or not use slurm (default False, requires slurmpy, may not work everywhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more files already existing and not moved\n"
     ]
    }
   ],
   "source": [
    "# dicom sorting example\n",
    "import pathlib\n",
    "import mrpyconvert\n",
    "unsorted_dicoms = pathlib.Path('/projects/lcni/jolinda/shared/TalapasClass/unsorted_dicoms/')\n",
    "mrpyconvert.SortDicoms(unsorted_dicoms, 'sorted_dicoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_dicoms\n",
      "`-- phantom_20171212_161421\n",
      "    |-- Series_1_AAHScout\n",
      "    |-- Series_2_AAHScout_MPR_sag\n",
      "    |-- Series_3_AAHScout_MPR_cor\n",
      "    |-- Series_4_AAHScout_MPR_tra\n",
      "    `-- Series_5_Resting1\n",
      "\n",
      "6 directories\n"
     ]
    }
   ],
   "source": [
    "!tree sorted_dicoms -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping series descriptions to BIDS entities\n",
    "Any dicoms that are to be converted must have their series descriptions mapped to the appropriate BIDS entities. GetSeriesNames will extract all series descriptions from your sorted input dicom folder to make it easier to define this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAHScout_32ch-head-coil',\n",
       " 'AAHScout_32ch-head-coil_MPR_cor',\n",
       " 'AAHScout_32ch-head-coil_MPR_sag',\n",
       " 'AAHScout_32ch-head-coil_MPR_tra',\n",
       " 'Flair_axial.sw',\n",
       " 'bold_mb3_g2_2mm_te25',\n",
       " 'mprage_p2',\n",
       " 'pcasl_hires_0.0',\n",
       " 'pcasl_hires_0.2',\n",
       " 'pcasl_hires_0.7',\n",
       " 'pcasl_hires_1.2',\n",
       " 'pcasl_hires_1.7',\n",
       " 'pcasl_hires_2.2',\n",
       " 'se_epi_mb3_g2_2mm_ap',\n",
       " 'se_epi_mb3_g2_2mm_pa',\n",
       " 'siemens_diff_3shell_ap',\n",
       " 'siemens_diff_3shell_lr',\n",
       " 'siemens_diff_3shell_pa',\n",
       " 'siemens_diff_3shell_rl',\n",
       " 't2_space_sag_p2_iso',\n",
       " 't2_tse_cor65slice_2avg.+',\n",
       " 'tof_fl3d_tra_p2_multi-slab',\n",
       " 'tof_fl3d_tra_p2_multi-slab_MIP_COR',\n",
       " 'tof_fl3d_tra_p2_multi-slab_MIP_SAG',\n",
       " 'tof_fl3d_tra_p2_multi-slab_MIP_TRA'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dicoms = pathlib.Path('/projects/lcni/dcm/lcni/Burggren/HEAT')\n",
    "mrpyconvert.GetSeriesNames(example_dicoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should be mapped to output file names using a dictionary. 'datatype' and 'suffix' are required. mrpyconvert does NOT check whether all required fields have been defined (eg, 'task' for bold images), that's up to you. Entries can be defined in any order; py2bids will format the output file names correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = mrpyconvert.bids_dict() # create a bids dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.add('mprage_p2', datatype = 'anat', suffix = 'T1w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.add('bold_mb3_g2_2mm_te25', datatype = 'func', suffix = 'bold', task = 'resting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some BIDS entities are also python keywords. In that case you can't use this function call:\n",
    "``bd.add('siemens_diff_3shell_ap', datatype = 'dwi', suffix = 'dwi', dir = 'ap') ``\n",
    "Instead, use the \"entities\" parameter. This parameter takes a dictionary as an argument:\n",
    "``bd.add('siemens_diff_3shell_ap', datatype = 'dwi', suffix = 'dwi', entities = {'dir':'ap'}) ``  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.add('siemens_diff_3shell_ap', datatype = 'dwi', suffix = 'dwi', entities = {'dir':'ap'})\n",
    "bd.add('siemens_diff_3shell_pa', datatype = 'dwi', suffix = 'dwi', entities = {'dir':'pa'})\n",
    "bd.add('siemens_diff_3shell_rl', datatype = 'dwi', suffix = 'dwi', entities = {'dir':'rl'})\n",
    "bd.add('siemens_diff_3shell_lr', datatype = 'dwi', suffix = 'dwi', entities = {'dir':'lr'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert things that aren't in the bids standard by including the \"nonstandard = True\" argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.add('pcasl_hires_0.0', datatype = 'perf', suffix = 'asl', acq = '0.0', nonstandard = True)\n",
    "bd.add('pcasl_hires_0.2', datatype = 'perf', suffix = 'asl', acq = '0.2', nonstandard = True)\n",
    "bd.add('pcasl_hires_0.7', datatype = 'perf', suffix = 'asl', acq = '0.7', nonstandard = True)\n",
    "bd.add('pcasl_hires_1.2', datatype = 'perf', suffix = 'asl', acq = '1.2', nonstandard = True)\n",
    "bd.add('pcasl_hires_1.7', datatype = 'perf', suffix = 'asl', acq = '1.7', nonstandard = True)\n",
    "bd.add('pcasl_hires_2.2', datatype = 'perf', suffix = 'asl', acq = '2.2', nonstandard = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprage_p2: sub-{}_run-{}_T1w\n",
      "bold_mb3_g2_2mm_te25: sub-{}_task-resting_run-{}_bold\n",
      "siemens_diff_3shell_ap: sub-{}_dir-ap_run-{}_dwi\n",
      "siemens_diff_3shell_pa: sub-{}_dir-pa_run-{}_dwi\n",
      "siemens_diff_3shell_rl: sub-{}_dir-rl_run-{}_dwi\n",
      "siemens_diff_3shell_lr: sub-{}_dir-lr_run-{}_dwi\n",
      "pcasl_hires_0.0: sub-{}_acq-0.0_run-{}_asl\n",
      "pcasl_hires_0.2: sub-{}_acq-0.2_run-{}_asl\n",
      "pcasl_hires_0.7: sub-{}_acq-0.7_run-{}_asl\n",
      "pcasl_hires_1.2: sub-{}_acq-1.2_run-{}_asl\n",
      "pcasl_hires_1.7: sub-{}_acq-1.7_run-{}_asl\n",
      "pcasl_hires_2.2: sub-{}_acq-2.2_run-{}_asl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the 'run' entity\n",
    "'run' will be replaced with the series number from the dicom file. This ensures that every run, including duplicates, will be converted, and that the output files are still BIDS compliant. If you want to use 'run' differently, or not use it at all, you'll need to rename your files after conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion\n",
    "Once you've defined your bids dictionary, call Convert with the input directory, output directory, and bids dictionary. Optionally, you can add \"slurm = True\" to submit conversion as a job to the cluster (this requires slurmpy and may not work on all or even most clusters, but if it works it will be MUCH faster). You must have dcm2niix and jq installed on your system. If your system uses lmod modules, include them as a list using the 'lmod' argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output directory\n",
    "bidsdir = pathlib.Path.home() / 'lcni' / 'bidsexample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about duplicate subjects\n",
    "The current iteration of mrpyconvert allows you to submit a directory with multiple subjects, but it assumes that there's only one of each! In my example input I have two sessions for subject 999 and that's a problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/lcni/dcm/lcni/Burggren/HEAT\n",
      "|-- HEAT002_20200303_102436\n",
      "|-- HEAT_999_20191211_105824\n",
      "|-- HEAT_999_20200127_132053\n",
      "`-- Phantom_20200116_151959\n",
      "\n",
      "4 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree {str(example_dicoms)} -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use a bit of python to only select the 2020 subjects, and convert one directory at a time instead of running `mrpyconvert.Convert(example_dicoms, bidsdir, bd)`. If this was a real study, I'd probably add the \"ses\" keyword to my dictionary, split my list of subject directories to convert into two lists, and have one with ses = 'one' in the bids dictionary and one with ses = 'two'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053\n",
      "Submitted batch job 12709482\n",
      "\n",
      "/projects/lcni/dcm/lcni/Burggren/HEAT/Phantom_20200116_151959\n",
      "Submitted batch job 12709483\n",
      "\n",
      "/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT002_20200303_102436\n",
      "Submitted batch job 12709484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subjectdir in example_dicoms.glob('*_2020*'):\n",
    "    print(subjectdir)\n",
    "    mrpyconvert.Convert(subjectdir, bidsdir, bd, lmod = ['dcm2niix', 'jq'], slurm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you wait for these to finish before continuing this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JobID                   JobName  Partition      State    Elapsed     MaxRSS \n",
      "-------------------- ------------------------- ---------- ---------- ---------- ---------- \n",
      "            12709482                   convert      short  COMPLETED   00:01:48            \n",
      "      12709482.batch                     batch             COMPLETED   00:01:48    302908K \n",
      "     12709482.extern                    extern             COMPLETED   00:01:48          0 \n"
     ]
    }
   ],
   "source": [
    "!sacct -j 12709482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JobID                   JobName  Partition      State    Elapsed     MaxRSS \n",
      "-------------------- ------------------------- ---------- ---------- ---------- ---------- \n",
      "            12709483                   convert      short  COMPLETED   00:00:26            \n",
      "      12709483.batch                     batch             COMPLETED   00:00:26          0 \n",
      "     12709483.extern                    extern             COMPLETED   00:00:26          0 \n"
     ]
    }
   ],
   "source": [
    "!sacct -j 12709483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JobID                   JobName  Partition      State    Elapsed     MaxRSS \n",
      "-------------------- ------------------------- ---------- ---------- ---------- ---------- \n",
      "            12709484                   convert      short  COMPLETED   00:01:49            \n",
      "      12709484.batch                     batch             COMPLETED   00:01:49    362000K \n",
      "     12709484.extern                    extern             COMPLETED   00:01:49          0 \n"
     ]
    }
   ],
   "source": [
    "!sacct -j 12709484"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from dcm2niix is in the slurm output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.7_run-14_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.7_run-14_asl.nii\"\n",
      "Conversion required 1.925818 seconds (0.070000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-1.2_run-13_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-1.2_run-13_asl.nii\"\n",
      "Conversion required 1.944295 seconds (0.040000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 55 DICOM file(s)\n",
      "Convert 55 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-rl_run-19_dwi (132x132x78x55)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-rl_run-19_dwi.nii\"\n",
      "Conversion required 15.794548 seconds (0.690000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 55 DICOM file(s)\n",
      "Convert 55 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-ap_run-17_dwi (132x132x78x55)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-ap_run-17_dwi.nii\"\n",
      "Conversion required 16.266726 seconds (0.680000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 55 DICOM file(s)\n",
      "Convert 55 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-pa_run-18_dwi (132x132x78x55)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-pa_run-18_dwi.nii\"\n",
      "Conversion required 16.463403 seconds (0.700000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 176 DICOM file(s)\n",
      "Convert 176 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/anat/sub-HEAT002_run-07_T1w (256x256x176x1)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/anat/sub-HEAT002_run-07_T1w.nii\"\n",
      "Conversion required 7.613492 seconds (0.530000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-1.7_run-12_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-1.7_run-12_asl.nii\"\n",
      "Conversion required 1.527571 seconds (0.040000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-2.2_run-11_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-2.2_run-11_asl.nii\"\n",
      "Conversion required 1.490765 seconds (0.040000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.0_run-16_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.0_run-16_asl.nii\"\n",
      "Conversion required 1.605713 seconds (0.040000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 12 DICOM file(s)\n",
      "Convert 12 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.2_run-15_asl (86x86x60x12)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/perf/sub-HEAT002_acq-0.2_run-15_asl.nii\"\n",
      "Conversion required 1.539256 seconds (0.050000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 164 DICOM file(s)\n",
      "Convert 164 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/func/sub-HEAT002_task-resting_run-10_bold (104x104x72x164)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/func/sub-HEAT002_task-resting_run-10_bold.nii\"\n",
      "Conversion required 25.034428 seconds (0.900000 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20200331  (JP2:OpenJPEG) (JP-LS:CharLS) GCC5.5.0 (64-bit Linux)\n",
      "Found 55 DICOM file(s)\n",
      "Convert 55 DICOM as /home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-lr_run-20_dwi (132x132x78x55)\n",
      "Compress: \"/bin/pigz\" -b 960 -n -f -6 \"/home/jolinda/lcni/bidsexample/sub-HEAT002/dwi/sub-HEAT002_dir-lr_run-20_dwi.nii\"\n",
      "Conversion required 15.803320 seconds (0.700000 for core code).\n"
     ]
    }
   ],
   "source": [
    "cat slurm-12709484.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jolinda/lcni/bidsexample\n",
      "|-- dataset_description.json\n",
      "|-- participants.json\n",
      "|-- participants.tsv\n",
      "|-- sub-HEAT002\n",
      "|   |-- anat\n",
      "|   |   |-- sub-HEAT002_run-07_T1w.json\n",
      "|   |   `-- sub-HEAT002_run-07_T1w.nii.gz\n",
      "|   |-- dwi\n",
      "|   |   |-- sub-HEAT002_dir-ap_run-17_bval\n",
      "|   |   |-- sub-HEAT002_dir-ap_run-17_bvec\n",
      "|   |   |-- sub-HEAT002_dir-ap_run-17_dwi.json\n",
      "|   |   |-- sub-HEAT002_dir-ap_run-17_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT002_dir-lr_run-20_bval\n",
      "|   |   |-- sub-HEAT002_dir-lr_run-20_bvec\n",
      "|   |   |-- sub-HEAT002_dir-lr_run-20_dwi.json\n",
      "|   |   |-- sub-HEAT002_dir-lr_run-20_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT002_dir-pa_run-18_bval\n",
      "|   |   |-- sub-HEAT002_dir-pa_run-18_bvec\n",
      "|   |   |-- sub-HEAT002_dir-pa_run-18_dwi.json\n",
      "|   |   |-- sub-HEAT002_dir-pa_run-18_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT002_dir-rl_run-19_bval\n",
      "|   |   |-- sub-HEAT002_dir-rl_run-19_bvec\n",
      "|   |   |-- sub-HEAT002_dir-rl_run-19_dwi.json\n",
      "|   |   `-- sub-HEAT002_dir-rl_run-19_dwi.nii.gz\n",
      "|   |-- func\n",
      "|   |   |-- sub-HEAT002_task-resting_run-10_bold.json\n",
      "|   |   `-- sub-HEAT002_task-resting_run-10_bold.nii.gz\n",
      "|   `-- perf\n",
      "|       |-- sub-HEAT002_acq-0.0_run-16_asl.json\n",
      "|       |-- sub-HEAT002_acq-0.0_run-16_asl.nii.gz\n",
      "|       |-- sub-HEAT002_acq-0.2_run-15_asl.json\n",
      "|       |-- sub-HEAT002_acq-0.2_run-15_asl.nii.gz\n",
      "|       |-- sub-HEAT002_acq-0.7_run-14_asl.json\n",
      "|       |-- sub-HEAT002_acq-0.7_run-14_asl.nii.gz\n",
      "|       |-- sub-HEAT002_acq-1.2_run-13_asl.json\n",
      "|       |-- sub-HEAT002_acq-1.2_run-13_asl.nii.gz\n",
      "|       |-- sub-HEAT002_acq-1.7_run-12_asl.json\n",
      "|       |-- sub-HEAT002_acq-1.7_run-12_asl.nii.gz\n",
      "|       |-- sub-HEAT002_acq-2.2_run-11_asl.json\n",
      "|       `-- sub-HEAT002_acq-2.2_run-11_asl.nii.gz\n",
      "|-- sub-HEAT999\n",
      "|   |-- anat\n",
      "|   |   |-- sub-HEAT999_run-07_T1w.json\n",
      "|   |   `-- sub-HEAT999_run-07_T1w.nii.gz\n",
      "|   |-- dwi\n",
      "|   |   |-- sub-HEAT999_dir-ap_run-11_bval\n",
      "|   |   |-- sub-HEAT999_dir-ap_run-11_bvec\n",
      "|   |   |-- sub-HEAT999_dir-ap_run-11_dwi.json\n",
      "|   |   |-- sub-HEAT999_dir-ap_run-11_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT999_dir-lr_run-14_bval\n",
      "|   |   |-- sub-HEAT999_dir-lr_run-14_bvec\n",
      "|   |   |-- sub-HEAT999_dir-lr_run-14_dwi.json\n",
      "|   |   |-- sub-HEAT999_dir-lr_run-14_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT999_dir-pa_run-12_bval\n",
      "|   |   |-- sub-HEAT999_dir-pa_run-12_bvec\n",
      "|   |   |-- sub-HEAT999_dir-pa_run-12_dwi.json\n",
      "|   |   |-- sub-HEAT999_dir-pa_run-12_dwi.nii.gz\n",
      "|   |   |-- sub-HEAT999_dir-rl_run-13_bval\n",
      "|   |   |-- sub-HEAT999_dir-rl_run-13_bvec\n",
      "|   |   |-- sub-HEAT999_dir-rl_run-13_dwi.json\n",
      "|   |   `-- sub-HEAT999_dir-rl_run-13_dwi.nii.gz\n",
      "|   |-- func\n",
      "|   |   |-- sub-HEAT999_task-resting_run-10_bold.json\n",
      "|   |   `-- sub-HEAT999_task-resting_run-10_bold.nii.gz\n",
      "|   `-- perf\n",
      "|       |-- sub-HEAT999_acq-0.0_run-21_asl.json\n",
      "|       |-- sub-HEAT999_acq-0.0_run-21_asl.nii.gz\n",
      "|       |-- sub-HEAT999_acq-0.2_run-20_asl.json\n",
      "|       |-- sub-HEAT999_acq-0.2_run-20_asl.nii.gz\n",
      "|       |-- sub-HEAT999_acq-0.7_run-19_asl.json\n",
      "|       |-- sub-HEAT999_acq-0.7_run-19_asl.nii.gz\n",
      "|       |-- sub-HEAT999_acq-1.2_run-18_asl.json\n",
      "|       |-- sub-HEAT999_acq-1.2_run-18_asl.nii.gz\n",
      "|       |-- sub-HEAT999_acq-1.7_run-17_asl.json\n",
      "|       |-- sub-HEAT999_acq-1.7_run-17_asl.nii.gz\n",
      "|       |-- sub-HEAT999_acq-2.2_run-16_asl.json\n",
      "|       `-- sub-HEAT999_acq-2.2_run-16_asl.nii.gz\n",
      "`-- sub-Phantom\n",
      "    `-- func\n",
      "        |-- sub-Phantom_task-resting_run-05_bold.json\n",
      "        `-- sub-Phantom_task-resting_run-05_bold.nii.gz\n",
      "\n",
      "12 directories, 69 files\n"
     ]
    }
   ],
   "source": [
    "!tree {str(bidsdir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id\tage\tsex\n",
      "sub-HEAT999\t25\tM\n",
      "sub-Phantom\t24\tO\n",
      "sub-HEAT002\t47\tF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we automatically created a participants file\n",
    "with open(bidsdir / 'participants.tsv') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"age\": {\n",
      "        \"Description\": \"age of participant\",\n",
      "        \"Units\": \"years\"\n",
      "    },\n",
      "    \"sex\": {\n",
      "        \"Description\": \"sex of participant\",\n",
      "        \"Levels\": {\n",
      "            \"M\": \"male\",\n",
      "            \"F\": \"female\",\n",
      "            \"O\": \"other\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(bidsdir / 'participants.json') as f:\n",
    "    print(json.dumps(json.load(f), indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also creates a dataset_description file for you. On talapas it will even attempt to fill out the authors with your name and the PI on the project (using the pirg structure in the dicom repository; in this example it gets it wrong but we can always go back and edit it later). If you don't want either of these files created just specify description_file = False and/or participant_file = False in your call to mrpyconvert.Convert()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"HEAT\",\n",
      "    \"BIDSVersion\": \"1.3.0\",\n",
      "    \"Authors\": [\n",
      "        \"Fred Sabb\",\n",
      "        \"Jolinda Smith\"\n",
      "    ],\n",
      "    \"Acknowledgements\": \"BIDS conversion was performed using dcm2niix and mrpyconvert.\",\n",
      "    \"ReferencesAndLinks\": [\n",
      "        \"Li X, Morgan PS, Ashburner J, Smith J, Rorden C (2016) The first step for neuroimaging data analysis: DICOM to NIfTI conversion. J Neurosci Methods. 264:47-56. doi: 10.1016/j.jneumeth.2016.03.001.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(bidsdir / 'dataset_description.json') as f:\n",
    "    print(json.dumps(json.load(f), indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing -- in our dicom files, certain fields used by dcm2niix to write the .json files are wrong. We can fix this if we know what they are. In our case the \"Institution\" fields are wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lewis_Building\n",
      "Department\n",
      "Franklin_Blvd_1440_Eugene_District_US_97403\n"
     ]
    }
   ],
   "source": [
    "with open(next(bidsdir.rglob('sub*.json'))) as f:\n",
    "    j = json.load(f)\n",
    "    print(j['InstitutionName'])\n",
    "    print(j['InstitutionalDepartmentName'])\n",
    "    print(j['InstitutionAddress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a dictionary object with the correct values; this particular problem is pervasive at LCNI so I've included it in the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'InstitutionName': 'University of Oregon',\n",
       " 'InstitutionalDepartmentName': 'LCNI',\n",
       " 'InstitutionAddress': 'Franklin_Blvd_1440_Eugene_Oregon_US_97403'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py2bids.lcni_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert again and include this in the argument \"json_mod\". Since we only need to change the .json files, we can include the dcm2niix flags '-b o -w 0' to skip converting the .nii.gz files. We don't have to set particpant_file = False and description_file = False, they'll come through unchanged, but I will for illustration purposes. (-w 0 is 'ignore duplicates'. You might think we want -w 1, 'overwrite', but that will delete the existing dicom files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053\n",
      "/projects/lcni/dcm/lcni/Burggren/HEAT/Phantom_20200116_151959\n",
      "/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT002_20200303_102436\n"
     ]
    }
   ],
   "source": [
    "for subjectdir in example_dicoms.glob('*_2020*'):\n",
    "    print(subjectdir)\n",
    "    py2bids.Convert(subjectdir, bidsdir, bd, json_mod = py2bids.lcni_corrections, \n",
    "                    dcm2niix_flags= '-b o -w 0', lmod = ['dcm2niix', 'jq'],\n",
    "                    participant_file = False, description_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of Oregon\n",
      "LCNI\n",
      "Franklin_Blvd_1440_Eugene_Oregon_US_97403\n"
     ]
    }
   ],
   "source": [
    "with open(next(bidsdir.rglob('sub*.json'))) as f:\n",
    "    j = json.load(f)\n",
    "    print(j['InstitutionName'])\n",
    "    print(j['InstitutionalDepartmentName'])\n",
    "    print(j['InstitutionAddress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see exactly what commands are being run, you can see most of them with the \"GenerateCSCommand\" function. This command can't take pathlib arguments (yet); convert them to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-1.7_run-17_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_17_pcasl_hires_1.7\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/dwi\" -f sub-HEAT999_dir-pa_run-12_dwi  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_12_siemens_diff_3shell_pa\"\n",
      "for x in /home/jolinda/lcni/bidsexample/sub-HEAT999/dwi/*dwi.bv*\n",
      "do mv $x ${x//dwi.}\n",
      "done\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/dwi\" -f sub-HEAT999_dir-ap_run-11_dwi  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_11_siemens_diff_3shell_ap\"\n",
      "for x in /home/jolinda/lcni/bidsexample/sub-HEAT999/dwi/*dwi.bv*\n",
      "do mv $x ${x//dwi.}\n",
      "done\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/dwi\" -f sub-HEAT999_dir-rl_run-13_dwi  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_13_siemens_diff_3shell_rl\"\n",
      "for x in /home/jolinda/lcni/bidsexample/sub-HEAT999/dwi/*dwi.bv*\n",
      "do mv $x ${x//dwi.}\n",
      "done\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/anat\" -f sub-HEAT999_run-07_T1w  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_7_mprage_p2\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-1.2_run-18_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_18_pcasl_hires_1.2\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-0.7_run-19_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_19_pcasl_hires_0.7\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/dwi\" -f sub-HEAT999_dir-lr_run-14_dwi  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_14_siemens_diff_3shell_lr\"\n",
      "for x in /home/jolinda/lcni/bidsexample/sub-HEAT999/dwi/*dwi.bv*\n",
      "do mv $x ${x//dwi.}\n",
      "done\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-0.2_run-20_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_20_pcasl_hires_0.2\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/func\" -f sub-HEAT999_task-resting_run-10_bold  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_10_bold_mb3_g2_2mm_te25\"\n",
      "jq '.TaskName=\"resting\"' /home/jolinda/lcni/bidsexample/sub-HEAT999/func/sub-HEAT999_task-resting_run-10_bold.json > /tmp/sub-HEAT999_task-resting_run-10_bold.json\n",
      "mv /tmp/sub-HEAT999_task-resting_run-10_bold.json /home/jolinda/lcni/bidsexample/sub-HEAT999/func/sub-HEAT999_task-resting_run-10_bold.json\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-0.0_run-21_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_21_pcasl_hires_0.0\"\n",
      "dcm2niix -ba n -l o -o \"/home/jolinda/lcni/bidsexample/sub-HEAT999/perf\" -f sub-HEAT999_acq-2.2_run-16_asl  \"/projects/lcni/dcm/lcni/Burggren/HEAT/HEAT_999_20200127_132053/Series_16_pcasl_hires_2.2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjectdir = next(example_dicoms.glob('*_2020*'))\n",
    "print(py2bids.GenerateCSCommand(str(subjectdir), str(bidsdir), bd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
